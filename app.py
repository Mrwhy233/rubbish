from flask import Flask, render_template, request, Response, jsonify, send_file
from bs4 import BeautifulSoup
import json
import requests
import time
import os
import csv
from io import StringIO

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

app = Flask(__name__)

# æœ¬åœ°å†å²è®°å½•æ–‡ä»¶
HISTORY_FILE = "history.json"


# ----------------------------------------------------
# å·¥å…·å‡½æ•°ï¼šåŠ è½½ä¸ä¿å­˜å†å²
# ----------------------------------------------------
def load_history():
    """è¯»å–å†å²è®°å½•"""
    if not os.path.exists(HISTORY_FILE):
        return []
    with open(HISTORY_FILE, "r", encoding="utf-8") as f:
        return json.load(f)


def save_history(entry):
    """ä¿å­˜æ–°çš„çˆ¬å–è®°å½•"""
    data = load_history()
    # è‹¥å†å²ä¸­å·²æœ‰ç›¸åŒURLï¼Œåˆ™è¦†ç›–
    for item in data:
        if item["url"] == entry["url"]:
            item.update(entry)
            break
    else:
        data.insert(0, entry)  # æœ€æ–°åœ¨æœ€å‰
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def delete_history(index):
    data = load_history()
    if 0 <= index < len(data):
        del data[index]
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    return False


# ---------------------------------------------------
# Selenium æ¨¡æ‹ŸåŠ è½½
# ---------------------------------------------------
def fetch_with_selenium(url, yield_log, retry_no_headless=False):
    """ä½¿ç”¨ Selenium æ¨¡æ‹Ÿæ‰“å¼€ç½‘é¡µ"""
    try:
        chrome_options = Options()
        if not retry_no_headless:
            chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("window-size=1920,1080")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument(
            "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/128.0.0.0 Safari/537.36"
        )

        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(40)

        mode = "ğŸ”’ å–æ¶ˆæ— ç•Œé¢æ¨¡å¼é‡æ–°å°è¯•åŠ è½½" if retry_no_headless else "ğŸš€ å¯åŠ¨æµè§ˆå™¨æ¨¡å¼åŠ è½½ç½‘é¡µ"
        yield_log(mode)
        driver.get(url)

        # ç­‰å¾…æ­£æ–‡åŠ è½½
        try:
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "article, .blog-content-box, #content_views, .article-content"))
            )
            yield_log("âœ… æ£€æµ‹åˆ°å†…å®¹åŠ è½½ã€‚")
        except Exception:
            yield_log("âš ï¸ æœªæ£€æµ‹åˆ°ç‰¹å®šå†…å®¹åŒºåŸŸï¼Œç»§ç»­...")

        # å‘ä¸‹æ»šåŠ¨ä»¥è§¦å‘æ‡’åŠ è½½
        last_height = driver.execute_script("return document.body.scrollHeight")
        for i in range(5):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
            yield_log(f"â†©ï¸ ç¬¬ {i+1} æ¬¡æ»šåŠ¨å®Œæˆ")

        html = driver.page_source
        driver.quit()
        yield_log("âœ… é¡µé¢åŠ è½½å®Œæ¯•ã€‚")
        return html

    except Exception as e:
        yield_log(f"âŒ Selenium å‡ºé”™: {e}")
        return None


# ---------------------------------------------------
# Flask ä¸»è·¯ç”±
# ---------------------------------------------------
@app.route('/')
def home():
    return render_template('index.html')


# -------------------- æ ¸å¿ƒçˆ¬å– ---------------------
@app.route('/stream', methods=['POST'])
def stream():
    data = request.get_json()
    url = data.get("url")

    def generate():
        def send_log(msg):
            yield f"data: {json.dumps({'log': msg})}\n\n"

        if not url:
            yield f"data: {json.dumps({'error': 'âŒ æœªæä¾›URL'})}\n\n"
            return

        try:
            yield from send_log(f"å¼€å§‹çˆ¬å– {url} ...")
            headers = {
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/128.0.0.0 Safari/537.36"
                )
            }

            html = None
            yield from send_log("ğŸŒ ä½¿ç”¨requestsè·å–ä¸­...")
            try:
                resp = requests.get(url, headers=headers, timeout=10)
                if resp.status_code in [403, 520, 521, 522, 523, 524]:
                    yield from send_log(f"âš ï¸ çŠ¶æ€ç  {resp.status_code}ï¼Œåˆ‡æ¢åˆ°æµè§ˆå™¨æ–¹å¼ã€‚")
                    html = fetch_with_selenium(url, lambda m: (yield from send_log(m)))
                else:
                    html = resp.text
                    yield from send_log("âœ… requestsæˆåŠŸã€‚")
            except Exception as e:
                yield from send_log(f"âš ï¸ requests å¤±è´¥: {e}")
                html = fetch_with_selenium(url, lambda m: (yield from send_log(m)))

            if not html:
                yield f"data: {json.dumps({'error': 'âŒ è·å–ç½‘é¡µå¤±è´¥'})}\n\n"
                return

            # ---- è§£æHTML ----
            soup = BeautifulSoup(html, "html.parser")
            title = soup.title.string.strip() if soup.title else "æ— æ ‡é¢˜"
            paragraphs = [p.get_text(strip=True) for p in soup.find_all('p') if p.get_text(strip=True)]
            links = [a['href'] for a in soup.find_all('a', href=True)]

            # ---- æ–°å¢ï¼šè¡¨æ ¼æå– ----
            tables_data = []
            tables = soup.find_all("table")
            for t in tables:
                headers = [th.get_text(strip=True) for th in t.find_all("th")]
                rows = []
                for tr in t.find_all("tr"):
                    cells = [td.get_text(strip=True) for td in tr.find_all("td")]
                    if cells:
                        rows.append(cells)
                if headers or rows:
                    tables_data.append({"headers": headers, "rows": rows})

            # ---- è‹¥æ£€æµ‹å®‰å…¨éªŒè¯åˆ™é‡è¯• ----
            if "å®‰å…¨éªŒè¯" in title or len(paragraphs) < 5:
                yield from send_log("âš ï¸ æ£€æµ‹å®‰å…¨éªŒè¯é¡µé¢ï¼Œé‡æ–°å°è¯•(å…³é—­æ— ç•Œé¢)")
                html_retry = fetch_with_selenium(url, lambda m: (yield from send_log(m)), retry_no_headless=True)
                if html_retry:
                    soup = BeautifulSoup(html_retry, "html.parser")
                    title = soup.title.string.strip() if soup.title else title
                    paragraphs = [p.get_text(strip=True) for p in soup.find_all('p') if p.get_text(strip=True)]
                    links = [a['href'] for a in soup.find_all('a', href=True)]
                    tables_data = []
                    tables = soup.find_all("table")
                    for t in tables:
                        headers = [th.get_text(strip=True) for th in t.find_all("th")]
                        rows = []
                        for tr in t.find_all("tr"):
                            cells = [td.get_text(strip=True) for td in tr.find_all("td")]
                            if cells:
                                rows.append(cells)
                        if headers or rows:
                            tables_data.append({"headers": headers, "rows": rows})

            paragraphs = list(dict.fromkeys(paragraphs))[:200]
            links = list(dict.fromkeys(links))[:200]

            result = {
                "url": url,
                "title": title,
                "paragraphs": paragraphs,
                "links": links,
                "tables": tables_data,  # âœ… æ–°å¢å­—æ®µ
                "time": time.strftime("%Y-%m-%d %H:%M:%S")
            }

            # ä¿å­˜å†å²è®°å½•
            save_history(result)
            yield from send_log(f"âœ… è·å–æˆåŠŸï¼Œå…± {len(paragraphs)} æ®µæ–‡å­—ï¼Œ{len(links)} ä¸ªé“¾æ¥ï¼Œ{len(tables_data)} ä¸ªè¡¨æ ¼ï¼Œå·²ä¿å­˜åˆ°å†å²è®°å½•ã€‚")

            yield f"data: {json.dumps({'result': result})}\n\n"

        except Exception as e:
            yield f"data: {json.dumps({'error': f'ä»»åŠ¡å‡ºé”™ï¼š{str(e)}'})}\n\n"

    return Response(generate(), mimetype="text/event-stream")


# -------------------- å†å²æ¥å£ ---------------------
@app.route("/history", methods=["GET"])
def history_list():
    """è·å–æ‰€æœ‰å†å²è®°å½•"""
    data = load_history()
    return jsonify(data)


@app.route("/history/<int:index>", methods=["GET"])
def get_history_item(index):
    """è·å–å•æ¡å†å²"""
    data = load_history()
    if 0 <= index < len(data):
        return jsonify(data[index])
    return jsonify({"error": "ç´¢å¼•è¶…å‡ºèŒƒå›´"}), 404


@app.route("/history/<int:index>", methods=["DELETE"])
def delete_history_item(index):
    """åˆ é™¤æŒ‡å®šå†å²"""
    ok = delete_history(index)
    return jsonify({"ok": ok})


@app.route("/history/export/<int:index>", methods=["GET"])
def export_history_item(index):
    """å¯¼å‡ºå†å²ä¸ºå•ç‹¬JSONæ–‡ä»¶"""
    data = load_history()
    if 0 <= index < len(data):
        filename = f"export_{index}.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data[index], f, ensure_ascii=False, indent=2)
        return send_file(filename, as_attachment=True)
    return jsonify({"error": "æœªæ‰¾åˆ°"}), 404


# -------------------- æ–°å¢ï¼šå¯¼å‡ºè¡¨æ ¼ä¸ºCSV ---------------------
@app.route("/history/export_table/<int:index>/<int:table_idx>", methods=["GET"])
def export_table_csv(index, table_idx):
    """å¯¼å‡ºæŸæ¡å†å²ä¸­çš„æŸä¸ªè¡¨æ ¼ä¸ºCSV"""
    data = load_history()
    if 0 <= index < len(data):
        item = data[index]
        tables = item.get("tables", [])
        if 0 <= table_idx < len(tables):
            table = tables[table_idx]
            csv_file = StringIO()
            writer = csv.writer(csv_file)
            if table["headers"]:
                writer.writerow(table["headers"])
            writer.writerows(table["rows"])
            csv_file.seek(0)

            filename = f"table_{index}_{table_idx}.csv"
            return Response(
                csv_file.getvalue(),
                mimetype="text/csv",
                headers={"Content-Disposition": f"attachment;filename={filename}"}
            )
    return jsonify({"error": "æœªæ‰¾åˆ°è¡¨æ ¼"}), 404


# -------------------- å¯åŠ¨ ---------------------
if __name__ == '__main__':
    print("ğŸš€ Flask + è¡¨æ ¼å¢å¼ºç‰ˆçˆ¬è™«å¯åŠ¨ï¼šhttp://127.0.0.1:5000")
    app.run(debug=True, threaded=True)